q()
help
# Adresse du dossier où vous travaillez
setwd("/home/simo/I3/AnalyseDeDonnees/Code")
# Packages utilisés dans la suite
library(MASS)
require(pls)
# Supprimer toutes les variables
rm(list=ls(all=TRUE))
# Adresse du dossier où vous travaillez
setwd("/home/simo/I3/AnalyseDeDonnees/Code")
# Packages utilisés dans la suite
library(MASS)
require(pls)
# Supprimer toutes les variables
rm(list=ls(all=TRUE))
# Adresse du dossier où vous travaillez
setwd("/home/simo/I3/AnalyseDeDonnees/Code")
# Packages utilisés dans la suite
library(MASS)
require(pls)
# Supprimer toutes les variables
rm(list=ls(all=TRUE))
# Utilisation de données sur data
# Affichage des informations
?Boston
# Affichage des données
print(Boston)
# Transformation des données
data <- Boston
data <- data.frame(y=Boston$medv,x1=Boston$lstat,x2=Boston$age,
x3=Boston$crim,x4=Boston$zn,x5=Boston$indus,
x6=Boston$chas,x7=Boston$nox,x8=Boston$rm,
x9=Boston$dis,x10=Boston$rad,x11=Boston$tax,
x12=Boston$ptratio,x13=Boston$black)
# Paramètres
n <- length(data$y)
alpha <- 0.05
## Mise en place de la régression linéaire [SIMPLE]
simpleLinearReg <- lm(y~x1, data=data)
## Mise en place de la régression linéaire [MULTIPLE]
linearReg <- lm(y~x1+x2, data=data)
# Affichage du résultat
summary(linearReg)
# Risque à 5% : tester la nullité des coefficients du modèle de régression.
numOfVariables <- 2
qt(1-alpha/2, n-numOfVariables-1)
qf(1-alpha/2, numOfVariables, n-numOfVariables-1)
# Intervalle de confiance
confint(linearReg)
numOfVariablesToTest = 1
qf(1-alpha/2, numOfVariablesToTest, n-numOfVariables-1)
anova(simpleLinearReg,linearReg)
simpleLinearRegx2 <- lm(y~x2, data=data)
anova(simpleLinearRegx2,linearReg)
# Prédiction
predict(linearReg,data.frame(x1=10,x2=72), interval="confidence")
predict(linearReg,data.frame(x1=10,x2=72), interval="prediction")
# Affichage des résidus en fonction de la prédiction
plot(linearReg$fitted.values, linearReg$residuals)
abline(0,0)
# Test de normalité des résidus
shapiro.test(resid(linearReg))
## Selection de variables (en utilisant TOUTES les variables)
fullLinearReg <- lm(y~., data=data)
back <- step(fullLinearReg, direction="backward", trace = 1)
formula(back)
null <- lm(y ~ 1, data=data)
forw <- step(null, scope=list(lower=null,upper=fullLinearReg),direction="forward", trace = 1)
formula(forw)
# Utilisation de l’ACP pour réduire la dimension du problème
# Test sur validation croisée
# Combien de composantes pour avoir 80 % de variance expliquée ?
redDim = pcr(y~.,data=data,scale=TRUE,validation="CV")
summary(redDim)
# Adresse du dossier où vous travaillez
setwd("/home/simo/I3/AnalyseDeDonnees/Code")
# Adresse du dossier où vous travaillez
setwd("/home/simo/I3/AnalyseDeDonnees/Code")
# Packages utilisés dans la suite
library(rpart)
# Supprimer toutes les variables
rm(list=ls(all=TRUE))
# Supprimer tous les graphiques déjà présents
graphics.off()
# Lecture des données d’apprentissage
data_train <- read.table("../Data/Data/synth_train.txt",header=T,sep="\t");
plot(data_train$x1, data_train$x2, pch=data_train$y, col=data_train$y,main="Training set")
legend("topleft", legend=c("classe1", "classe2"), pch=1:2, col=1:2)
# Adresse du dossier où vous travaillez
setwd("/home/simo/I3/AnalyseDeDonnees/Code")
# Packages utilisés dans la suite
library(rpart)
# Supprimer toutes les variables
rm(list=ls(all=TRUE))
# Supprimer tous les graphiques déjà présents
graphics.off()
# Lecture des données d’apprentissage
data_train <- read.table("../Data/Data/synth_train.txt",header=T,sep="\t");
data_train
plot(data_train$x1, data_train$x2, pch=data_train$y, col=data_train$y,main="Training set")
legend("topleft", legend=c("classe1", "classe2"), pch=1:2, col=1:2)
# Création de la sortie (à mettre sous le format facteur sinon
# un modèle de régression est créé)
data_train$y <- as.factor(data_train$y)
tree <- rpart(y~., data = data_train)
print(tree)
summary(tree)
help(tree)
help(rpart)
# Adresse du dossier où vous travaillez
setwd("/home/simo/I3/AnalyseDeDonnees/Code")
# Packages utilisés dans la suite
library(class)
library(caret)
library(ROCR)
# Supprimer toutes les variables
rm(list=ls(all=TRUE))
# Adresse du dossier où vous travaillez
setwd("/home/simo/I3/AnalyseDeDonnees/Code")
# Packages utilisés dans la suite
library(class)
library(caret)
library(ROCR)
# Supprimer toutes les variables
rm(list=ls(all=TRUE))
# Supprimer tous les graphiques déjà présents
graphics.off()
# Lecture des données d’apprentissage
data_train <- read.table("../Data/Data/synth_train.txt",header=T,sep="\t");
print(data_train)
# Séparation des données et de la sortie
data_train_x <- data.frame(x1=data_train$x1,x2=data_train$x2)
data_train_x
# Lecture des données test
data_test <- read.table("../Data/Data/synth_test.txt",header=T,sep="\t");
print(data_test)
# Séparation des données et de la sortie
data_test_x <- data.frame(x1=data_test$x1,x2=data_test$x2)
# Graphique des données (colorées par la sortie y)
plot(data_train$x1,data_train$x2,col=data_train$y,pch=16)
#5. Appliquer les k-plus proches voisins sur les données d’apprentissage :
# nombre de voisins (par ex proche de la racine carré du nombre d’obs)
num_of_neigh <- 10
data_train_predict <- knn(train=data_train_x,test=data_train_x, cl=data_train$y,k=num_of_neigh)
# Affichage des résultats (étoile)
par(new=T)
plot(data_train$x1,data_train$x2,col=data_train_predict,pch=8)
# Calcul du taux d’erreur
error_rate <- mean(data_train_predict != data_train$y)
cat("error_rate using train data = ",error_rate)
#6. Appliquer les k-plus proches voisins sur les données test :
data_test_predict <- knn(train=data_train_x,test=data_test_x,cl=data_train$y,k=num_of_neigh)
# Affichage des données (cercle)
plot(data_train$x1,data_train$x2,col=data_train$y,pch=16)
par(new=T)
# Affichage des résultats (étoile)
plot(data_test$x1,data_test$x2,col=data_test_predict,pch=8)
# Affichage des vraies valeurs (triangle)
par(new=T)
plot(data_test$x1,data_test$x2,col=data_test$y,pch=2)
# Calcul du taux d’erreur
error_rate <- mean(data_test_predict != data_test$y)
cat("error_rate using test data = ",error_rate)
# Matrice de confusion
confmat = table(data_test_predict,data_test$y)
print("Confusion Matrix")
print(confmat)
# vrais positifs + vrais negatifs + faux positifs + faux négatifs
TP = confmat[1,1]; TN = confmat[2,2]; FP = confmat[1,2]; FN = confmat[2,1];
# Sensibilité (sensitivity ; TPR = true positive rate)
TPR = TP/(TP+FN)
cat("TPR",TPR,"\n")
# Spécificité (specificity ; TNR = true negative rate)
TNR = TN/(TN+FP)
cat("TNR",TNR,"\n")
# Précision (precision ; positive predictive value)
PPV = TP/(TP+FP)
cat("PPV",PPV,"\n")
# se compare à la prévalence (prevalence)
cat("Prev =",length(data_test$y[data_test$y==1])/length(data_test$y),"\n")
cat("F-score = ",2 * TPR * PPV / (TPR+PPV),"\n")
# Explication visuelle de l’importance de la valeur de k (nb de voisins)
# Construction de la grille
gridx1 <- seq(from=min(data_train$x1),to=max(data_train$x1),length.out=50)
gridx2 <- seq(from=min(data_train$x2),to=max(data_train$x2),length.out=50)
grid <- expand.grid(x1 = gridx1, x2 = gridx2)
data_grid_x <- data.frame(x1=grid[,1],x2=grid[,2])
# k plus proches voisins avec application sur les données de la grille
num_of_neigh_grid <- c(1,5,10,15,20,30)
par(mfrow=c(2,length(num_of_neigh_grid)/2))
for (i in 1:length(num_of_neigh_grid))
{
num_of_n <- num_of_neigh_grid[i]
data_g_pr <- knn(train=data_train_x,test=data_grid_x, cl=data_train$y,k=num_of_n)
plot(data_train$x1,data_train$x2,col=data_train$y,pch=16)
title(paste("num of neighbours = ",toString(num_of_n)))
par(new=T)
plot(data_grid_x$x1,data_grid_x$x2,col=data_g_pr,pch=8,cex=0.5,ann=FALSE)
}
# k plus proches voisins avec les probas
data_test_predict_with_proba <- knn(train=data_train_x,test=data_test_x,cl=data_train$y,k=num_of_neigh,prob=TRUE)
# Calcul du score
score <- attr(data_test_predict_with_proba, "prob")
score <- ifelse(data_test_predict_with_proba == "1", 1-score, score)
pred_knn <- prediction(score, data_test$y)
perf <- performance(pred_knn, "tpr", "fpr")
plot(perf,colorize=TRUE)
par(new=T)
plot(c(0,1),c(0,1),type="l",ann=FALSE)
# Aire sous la courbe
AUC <- performance(pred_knn, "auc")@y.values[[1]]
cat("AUC = ", AUC)
# Choix du seuil
result <- NULL
threshold <- seq(0,1,len=11)
for (s in threshold)
{
test <- as.integer(score>=s)+1
result <- c(result,1-mean(test != data_test$y))
}
plot(threshold,result,type="l")
cat("Meilleur seuil ", threshold[which.max(result)])
# Adresse du dossier où vous travaillez
setwd("/home/simo/I3/AnalyseDeDonnees/Code")
# Packages utilisés dans la suite
library(class)
library(caret)
library(ROCR)
# Supprimer toutes les variables
rm(list=ls(all=TRUE))
# Supprimer tous les graphiques déjà présents
graphics.off()
# Lecture des données d’apprentissage
data_train <- read.table("../Data/Data/synth_train.txt",header=T,sep="\t");
print(data_train)
# Séparation des données et de la sortie
data_train_x <- data.frame(x1=data_train$x1,x2=data_train$x2)
# Lecture des données test
data_test <- read.table("../Data/Data/synth_test.txt",header=T,sep="\t");
print(data_test)
# Séparation des données et de la sortie
data_test_x <- data.frame(x1=data_test$x1,x2=data_test$x2)
# Graphique des données (colorées par la sortie y)
plot(data_train$x1,data_train$x2,col=data_train$y,pch=16)
#5. Appliquer les k-plus proches voisins sur les données d’apprentissage :
# nombre de voisins (par ex proche de la racine carré du nombre d’obs)
num_of_neigh <- 10
data_train_predict <- knn(train=data_train_x,test=data_train_x, cl=data_train$y,k=num_of_neigh)
# Affichage des résultats (étoile)
par(new=T)
plot(data_train$x1,data_train$x2,col=data_train_predict,pch=8)
# Calcul du taux d’erreur
error_rate <- mean(data_train_predict != data_train$y)
cat("error_rate using train data = ",error_rate)
#6. Appliquer les k-plus proches voisins sur les données test :
data_test_predict <- knn(train=data_train_x,test=data_test_x,cl=data_train$y,k=num_of_neigh)
# Affichage des données (cercle)
plot(data_train$x1,data_train$x2,col=data_train$y,pch=16)
par(new=T)
# Affichage des résultats (étoile)
plot(data_test$x1,data_test$x2,col=data_test_predict,pch=8)
# Affichage des vraies valeurs (triangle)
par(new=T)
plot(data_test$x1,data_test$x2,col=data_test$y,pch=2)
# Calcul du taux d’erreur
error_rate <- mean(data_test_predict != data_test$y)
cat("error_rate using test data = ",error_rate)
# Matrice de confusion
confmat = table(data_test_predict,data_test$y)
print("Confusion Matrix")
print(confmat)
# vrais positifs + vrais negatifs + faux positifs + faux négatifs
TP = confmat[1,1]; TN = confmat[2,2]; FP = confmat[1,2]; FN = confmat[2,1];
# Sensibilité (sensitivity ; TPR = true positive rate)
TPR = TP/(TP+FN)
cat("TPR",TPR,"\n")
# Spécificité (specificity ; TNR = true negative rate)
TNR = TN/(TN+FP)
cat("TNR",TNR,"\n")
# Précision (precision ; positive predictive value)
PPV = TP/(TP+FP)
cat("PPV",PPV,"\n")
# se compare à la prévalence (prevalence)
cat("Prev =",length(data_test$y[data_test$y==1])/length(data_test$y),"\n")
cat("F-score = ",2 * TPR * PPV / (TPR+PPV),"\n")
# Explication visuelle de l’importance de la valeur de k (nb de voisins)
# Construction de la grille
gridx1 <- seq(from=min(data_train$x1),to=max(data_train$x1),length.out=50)
gridx2 <- seq(from=min(data_train$x2),to=max(data_train$x2),length.out=50)
grid <- expand.grid(x1 = gridx1, x2 = gridx2)
data_grid_x <- data.frame(x1=grid[,1],x2=grid[,2])
# k plus proches voisins avec application sur les données de la grille
num_of_neigh_grid <- c(1,5,10,15,20,30)
par(mfrow=c(2,length(num_of_neigh_grid)/2))
for (i in 1:length(num_of_neigh_grid))
{
num_of_n <- num_of_neigh_grid[i]
data_g_pr <- knn(train=data_train_x,test=data_grid_x, cl=data_train$y,k=num_of_n)
plot(data_train$x1,data_train$x2,col=data_train$y,pch=16)
title(paste("num of neighbours = ",toString(num_of_n)))
par(new=T)
plot(data_grid_x$x1,data_grid_x$x2,col=data_g_pr,pch=8,cex=0.5,ann=FALSE)
}
# k plus proches voisins avec les probas
data_test_predict_with_proba <- knn(train=data_train_x,test=data_test_x,cl=data_train$y,k=num_of_neigh,prob=TRUE)
# Calcul du score
score <- attr(data_test_predict_with_proba, "prob")
score <- ifelse(data_test_predict_with_proba == "1", 1-score, score)
pred_knn <- prediction(score, data_test$y)
perf <- performance(pred_knn, "tpr", "fpr")
plot(perf,colorize=TRUE)
par(new=T)
plot(c(0,1),c(0,1),type="l",ann=FALSE)
# Aire sous la courbe
AUC <- performance(pred_knn, "auc")@y.values[[1]]
cat("AUC = ", AUC)
# Choix du seuil
result <- NULL
threshold <- seq(0,1,len=11)
for (s in threshold)
{
test <- as.integer(score>=s)+1
result <- c(result,1-mean(test != data_test$y))
}
plot(threshold,result,type="l")
cat("Meilleur seuil ", threshold[which.max(result)])
